{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import statistics as stat\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_fill__1 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__2 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__3 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__4 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__5 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__6 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__7 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__8 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__9 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__10 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill__11 = np.zeros((train_data.shape[0]), float)\n",
    "train_data['softmax'] = self_fill__1\n",
    "train_data['tanh'] = self_fill__2\n",
    "train_data['linear'] = self_fill__3\n",
    "train_data['dropout'] = self_fill__4\n",
    "train_data['batchnorm'] = self_fill__5\n",
    "train_data['flatten'] = self_fill__6\n",
    "train_data['conv'] = self_fill__7\n",
    "train_data['selu'] = self_fill__8\n",
    "train_data['leaky_relu'] = self_fill__9\n",
    "train_data['relu'] = self_fill__10\n",
    "train_data['maxpool'] = self_fill__11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_fill_1 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill_2 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill_3 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill_4 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill_5 = np.zeros((train_data.shape[0]), float)\n",
    "self_fill_6 = np.zeros((train_data.shape[0]), float)\n",
    "train_data['init_params_mu_stdev'] = self_fill_3\n",
    "train_data['init_params_mu_mean'] = self_fill_4\n",
    "train_data['init_params_std_stdev'] = self_fill_1\n",
    "train_data['init_params_std_mean'] = self_fill_2\n",
    "train_data['init_params_l2_stdev'] = self_fill_5\n",
    "train_data['init_params_l2_mean'] = self_fill_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "train_data['arch_and_hp'][k].count('linear') + train_data['arch_and_hp'][k].count('batchnorm') + train_data['arch_and_hp'][k].count('conv')\n",
    "# train_data['arch_and_hp'][k].count('softmax')\n",
    "#             train_data['leaky_relu'][k] = train_data['arch_and_hp'][k].count('leaky_relu')\n",
    "#             train_data['relu'][k] = train_data['arch_and_hp'][k].count('relu')\n",
    "#             train_data['maxpool'][k] = train_data['arch_and_hp'][k].count('maxpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[3.508430242538452, 0.41103067994117737, 20.853721618652344, 0.7421039938926697, 206.51507568359375, 7.78318452835083, 20.15958023071289, 1.1896897554397583, 22.89699363708496, 0.5932527184486389]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['init_params_l2'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.34725773334503174, 0.34454283118247986, 0.2120860517024994, 0.0037662440445274115, 0.4686237871646881, 0.2313128262758255, 0.2733633518218994, 0.06532274186611176, 0.33836954832077026, 1.4938384294509888]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['init_params_std'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.014136802405118942, 0.05712495744228363, -0.0016092772129923105, 0.0008914984646253288, 0.5923929810523987, 0.04065660759806633, 8.459958917228505e-05, -0.0014921020483598113, -0.00011485421418910846, -1.7618058919906616]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['init_params_mu'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = train_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for k in range(train_data.shape[0]):\n",
    "    if my_filter['arch_and_hp'][k] == False:\n",
    "        if type(train_data['arch_and_hp'][k]) == str:\n",
    "            train_data['softmax'][k] = train_data['arch_and_hp'][k].count('softmax')\n",
    "            train_data['tanh'][k] = train_data['arch_and_hp'][k].count('tanh')\n",
    "            train_data['linear'][k] = train_data['arch_and_hp'][k].count('linear')\n",
    "            train_data['dropout'][k] = train_data['arch_and_hp'][k].count('dropout')\n",
    "            train_data['batchnorm'][k] = train_data['arch_and_hp'][k].count('batchnorm')\n",
    "            train_data['flatten'][k] = train_data['arch_and_hp'][k].count('flatten')\n",
    "            train_data['conv'][k] = train_data['arch_and_hp'][k].count('conv')\n",
    "            train_data['selu'][k] = train_data['arch_and_hp'][k].count('selu')\n",
    "            train_data['leaky_relu'][k] = train_data['arch_and_hp'][k].count('leaky_relu')\n",
    "            train_data['relu'][k] = train_data['arch_and_hp'][k].count('relu')\n",
    "            train_data['maxpool'][k] = train_data['arch_and_hp'][k].count('maxpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total_1 = 0\n",
    "total_2 = 0\n",
    "for k in range(train_data.shape[0]):\n",
    "    if my_filter['init_params_mu'][k] == False:\n",
    "        if type(train_data['init_params_mu'][k]) == str and len(train_data['init_params_mu'][k]) >= 2 and train_data['init_params_mu'][k][0] == '[' and train_data['init_params_mu'][k][-1] == ']':\n",
    "            mean_1 = stat.stdev([float(i) for i in train_data['init_params_mu'][k][1:-1].split(',')])\n",
    "            mean_2 = stat.mean([float(i) for i in train_data['init_params_mu'][k][1:-1].split(',')])\n",
    "            train_data['init_params_mu_stdev'][k] = mean_1\n",
    "            train_data['init_params_mu_mean'][k] = mean_2\n",
    "            total_1 += mean_1\n",
    "            total_2 += mean_2\n",
    "            count += 1\n",
    "\n",
    "for k in range(train_data.shape[0]):\n",
    "    if my_filter['init_params_mu'][k]:\n",
    "        train_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_mu_mean'][k] = total_2 / count\n",
    "    elif type(train_data['init_params_mu'][k]) != str:\n",
    "        train_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_mu_mean'][k] = total_2 / count\n",
    "    elif len(train_data['init_params_mu'][k]) < 2:\n",
    "        train_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_mu_mean'][k] = total_2 / count\n",
    "    elif train_data['init_params_mu'][k][0] != '[':\n",
    "        train_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_mu_mean'][k] = total_2 / count\n",
    "    elif train_data['init_params_mu'][k][-1] != ']':\n",
    "        train_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_mu_mean'][k] = total_2 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total_1 = 0\n",
    "total_2 = 0\n",
    "for k in range(train_data.shape[0]):\n",
    "    if my_filter['init_params_std'][k] == False:\n",
    "        if type(train_data['init_params_std'][k]) == str and len(train_data['init_params_std'][k]) >= 2 and train_data['init_params_std'][k][0] == '[' and train_data['init_params_std'][k][-1] == ']':\n",
    "            mean_1 = stat.stdev([float(i) for i in train_data['init_params_std'][k][1:-1].split(',')])\n",
    "            mean_2 = stat.mean([float(i) for i in train_data['init_params_std'][k][1:-1].split(',')])\n",
    "            train_data['init_params_std_stdev'][k] = mean_1\n",
    "            train_data['init_params_std_mean'][k] = mean_2\n",
    "            total_1 += mean_1\n",
    "            total_2 += mean_2\n",
    "            count += 1\n",
    "\n",
    "for k in range(train_data.shape[0]):\n",
    "    if my_filter['init_params_std'][k]:\n",
    "        train_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_std_mean'][k] = total_2 / count\n",
    "    elif type(train_data['init_params_std'][k]) != str:\n",
    "        train_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_std_mean'][k] = total_2 / count\n",
    "    elif len(train_data['init_params_std'][k]) < 2:\n",
    "        train_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_std_mean'][k] = total_2 / count\n",
    "    elif train_data['init_params_std'][k][0] != '[':\n",
    "        train_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_std_mean'][k] = total_2 / count\n",
    "    elif train_data['init_params_std'][k][-1] != ']':\n",
    "        train_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_std_mean'][k] = total_2 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total_1 = 0\n",
    "total_2 = 0\n",
    "for k in range(train_data.shape[0]):\n",
    "    if my_filter['init_params_l2'][k] == False:\n",
    "        if type(train_data['init_params_l2'][k]) == str and len(train_data['init_params_l2'][k]) >= 2 and train_data['init_params_l2'][k][0] == '[' and train_data['init_params_l2'][k][-1] == ']':\n",
    "            mean_1 = stat.stdev([float(i) for i in train_data['init_params_l2'][k][1:-1].split(',')])\n",
    "            mean_2 = stat.mean([float(i) for i in train_data['init_params_l2'][k][1:-1].split(',')])\n",
    "            train_data['init_params_l2_stdev'][k] = mean_1\n",
    "            train_data['init_params_l2_mean'][k] = mean_2\n",
    "            total_1 += mean_1\n",
    "            total_2 += mean_2\n",
    "            count += 1\n",
    "\n",
    "for k in range(train_data.shape[0]):\n",
    "    if my_filter['init_params_l2'][k]:\n",
    "        train_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_l2_mean'][k] = total_2 / count\n",
    "    elif type(train_data['init_params_l2'][k]) != str:\n",
    "        train_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_l2_mean'][k] = total_2 / count\n",
    "    elif len(train_data['init_params_l2'][k]) < 2:\n",
    "        train_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_l2_mean'][k] = total_2 / count\n",
    "    elif train_data['init_params_l2'][k][0] != '[':\n",
    "        train_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_l2_mean'][k] = total_2 / count\n",
    "    elif train_data['init_params_l2'][k][-1] != ']':\n",
    "        train_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        train_data['init_params_l2_mean'][k] = total_2 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(train_data['val_error'])\n",
    "y2 = np.array(train_data['train_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(train_data[['init_params_mu_stdev', 'init_params_mu_mean', 'init_params_std_stdev', 'init_params_std_mean', 'init_params_l2_stdev', 'init_params_l2_mean',\n",
    "        'epochs', 'number_parameters', \n",
    "        'softmax', 'tanh', 'linear', 'dropout', 'batchnorm', 'flatten', 'conv', 'selu', 'leaky_relu', 'relu', 'maxpool',\n",
    "        'val_accs_0', 'val_accs_10', 'val_accs_20', 'val_accs_30', \n",
    "        'val_accs_40', 'val_accs_41', 'val_accs_42', 'val_accs_43', 'val_accs_44',\n",
    "       'val_accs_45', 'val_accs_46', 'val_accs_47', 'val_accs_48', 'val_accs_49',\n",
    "        'val_losses_0', 'val_losses_10', 'val_losses_20', 'val_losses_30', \n",
    "        'val_losses_40', 'val_losses_41', 'val_losses_42',\n",
    "       'val_losses_43', 'val_losses_44', 'val_losses_45', 'val_losses_46',\n",
    "       'val_losses_47', 'val_losses_48', 'val_losses_49']])\n",
    "x2 = np.array(train_data[['init_params_mu_stdev', 'init_params_mu_mean', 'init_params_std_stdev', 'init_params_std_mean', 'init_params_l2_stdev', 'init_params_l2_mean',\n",
    "        'epochs', 'number_parameters', \n",
    "        'softmax', 'tanh', 'linear', 'dropout', 'batchnorm', 'flatten', 'conv', 'selu', 'leaky_relu', 'relu', 'maxpool',\n",
    "        'train_accs_0', 'train_accs_10', 'train_accs_20', 'train_accs_30', \n",
    "       'train_accs_40', 'train_accs_41', 'train_accs_42', 'train_accs_43', 'train_accs_44',\n",
    "       'train_accs_45', 'train_accs_46', 'train_accs_47', 'train_accs_48', 'train_accs_49',\n",
    "        'train_losses_0', 'train_losses_10', 'train_losses_20', 'train_losses_30',\n",
    "        'train_losses_40', 'train_losses_41',\n",
    "       'train_losses_42', 'train_losses_43', 'train_losses_44',\n",
    "       'train_losses_45', 'train_losses_46', 'train_losses_47',\n",
    "       'train_losses_48', 'train_losses_49']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8661107184597876, 0.9531040787516835)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum_1 = 0\n",
    "# sum_2 = 0\n",
    "# model1 = []\n",
    "# model2 = []\n",
    "# model1_score_train = []\n",
    "model1_score_test = []\n",
    "# model2_score_train = []\n",
    "model2_score_test = []\n",
    "for i in range(200):\n",
    "    regr1 = linear_model.LinearRegression()\n",
    "    regr2 = linear_model.LinearRegression()\n",
    "    x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y1, test_size=0.05)\n",
    "    x2_train, x2_test, y2_train, y2_test = train_test_split(x2, y2, test_size=0.05)\n",
    "    regr1.fit(x1_train, y1_train)\n",
    "    regr2.fit(x2_train, y2_train)\n",
    "#     model1.append(regr1)\n",
    "#     model2.append(regr2)\n",
    "#     y1_predict_train = regr1.predict(x1_train)\n",
    "    y1_predict_test = regr1.predict(x1_test)\n",
    "#     y2_predict_train = regr2.predict(x2_train)\n",
    "    y2_predict_test = regr2.predict(x2_test)\n",
    "#     model1_score_train.append(r2_score(y1_predict_train, y1_train))\n",
    "    model1_score_test.append(r2_score(y1_predict_test, y1_test))\n",
    "#     model2_score_train.append(r2_score(y2_predict_train, y2_train))\n",
    "    model2_score_test.append(r2_score(y2_predict_test, y2_test))\n",
    "# avg1 = np.array(model1_score_test) * 0.2 + np.array(model1_score_train) * 0.8\n",
    "# avg2 = np.array(model2_score_test) * 0.2 + np.array(model2_score_train) * 0.8\n",
    "(stat.mean(model1_score_test), stat.mean(model2_score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr1 = linear_model.LinearRegression()\n",
    "regr2 = linear_model.LinearRegression()\n",
    "regr1.fit(x1, y1)\n",
    "regr2.fit(x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8870296702819231"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_predict = regr1.predict(x1)\n",
    "r2_score(y1_predict, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9614779009134996"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2_predict = regr2.predict(x2)\n",
    "r2_score(y2_predict, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_fill__1 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__2 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__3 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__4 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__5 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__6 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__7 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__8 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__9 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__10 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill__11 = np.zeros((test_data.shape[0]), float)\n",
    "test_data['softmax'] = self_fill__1\n",
    "test_data['tanh'] = self_fill__2\n",
    "test_data['linear'] = self_fill__3\n",
    "test_data['dropout'] = self_fill__4\n",
    "test_data['batchnorm'] = self_fill__5\n",
    "test_data['flatten'] = self_fill__6\n",
    "test_data['conv'] = self_fill__7\n",
    "test_data['selu'] = self_fill__8\n",
    "test_data['leaky_relu'] = self_fill__9\n",
    "test_data['relu'] = self_fill__10\n",
    "test_data['maxpool'] = self_fill__11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_fill_1 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill_2 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill_3 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill_4 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill_5 = np.zeros((test_data.shape[0]), float)\n",
    "self_fill_6 = np.zeros((test_data.shape[0]), float)\n",
    "test_data['init_params_mu_stdev'] = self_fill_3\n",
    "test_data['init_params_mu_mean'] = self_fill_4\n",
    "test_data['init_params_std_stdev'] = self_fill_1\n",
    "test_data['init_params_std_mean'] = self_fill_2\n",
    "test_data['init_params_l2_stdev'] = self_fill_5\n",
    "test_data['init_params_l2_mean'] = self_fill_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_filter = test_data.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for k in range(test_data.shape[0]):\n",
    "    if my_filter['arch_and_hp'][k] == False:\n",
    "        if type(test_data['arch_and_hp'][k]) == str:\n",
    "            test_data['softmax'][k] = test_data['arch_and_hp'][k].count('softmax')\n",
    "            test_data['tanh'][k] = test_data['arch_and_hp'][k].count('tanh')\n",
    "            test_data['linear'][k] = test_data['arch_and_hp'][k].count('linear')\n",
    "            test_data['dropout'][k] = test_data['arch_and_hp'][k].count('dropout')\n",
    "            test_data['batchnorm'][k] = test_data['arch_and_hp'][k].count('batchnorm')\n",
    "            test_data['flatten'][k] = test_data['arch_and_hp'][k].count('flatten')\n",
    "            test_data['conv'][k] = test_data['arch_and_hp'][k].count('conv')\n",
    "            test_data['selu'][k] = test_data['arch_and_hp'][k].count('selu')\n",
    "            test_data['leaky_relu'][k] = test_data['arch_and_hp'][k].count('leaky_relu')\n",
    "            test_data['relu'][k] = test_data['arch_and_hp'][k].count('relu')\n",
    "            test_data['maxpool'][k] = test_data['arch_and_hp'][k].count('maxpool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total_1 = 0\n",
    "total_2 = 0\n",
    "for k in range(test_data.shape[0]):\n",
    "    if my_filter['init_params_mu'][k] == False:\n",
    "        if type(test_data['init_params_mu'][k]) == str and len(test_data['init_params_mu'][k]) >= 2 and test_data['init_params_mu'][k][0] == '[' and test_data['init_params_mu'][k][-1] == ']':\n",
    "            mean_1 = stat.stdev([float(i) for i in test_data['init_params_mu'][k][1:-1].split(',')])\n",
    "            mean_2 = stat.mean([float(i) for i in test_data['init_params_mu'][k][1:-1].split(',')])\n",
    "            test_data['init_params_mu_stdev'][k] = mean_1\n",
    "            test_data['init_params_mu_mean'][k] = mean_2\n",
    "            total_1 += mean_1\n",
    "            total_2 += mean_2\n",
    "            count += 1\n",
    "\n",
    "for k in range(test_data.shape[0]):\n",
    "    if my_filter['init_params_mu'][k]:\n",
    "        test_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_mu_mean'][k] = total_2 / count\n",
    "    elif type(test_data['init_params_mu'][k]) != str:\n",
    "        test_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_mu_mean'][k] = total_2 / count\n",
    "    elif len(test_data['init_params_mu'][k]) < 2:\n",
    "        test_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_mu_mean'][k] = total_2 / count\n",
    "    elif test_data['init_params_mu'][k][0] != '[':\n",
    "        test_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_mu_mean'][k] = total_2 / count\n",
    "    elif test_data['init_params_mu'][k][-1] != ']':\n",
    "        test_data['init_params_mu_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_mu_mean'][k] = total_2 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total_1 = 0\n",
    "total_2 = 0\n",
    "for k in range(test_data.shape[0]):\n",
    "    if my_filter['init_params_std'][k] == False:\n",
    "        if type(test_data['init_params_std'][k]) == str and len(test_data['init_params_std'][k]) >= 2 and test_data['init_params_std'][k][0] == '[' and test_data['init_params_std'][k][-1] == ']':\n",
    "            mean_1 = stat.stdev([float(i) for i in test_data['init_params_std'][k][1:-1].split(',')])\n",
    "            mean_2 = stat.mean([float(i) for i in test_data['init_params_std'][k][1:-1].split(',')])\n",
    "            test_data['init_params_std_stdev'][k] = mean_1\n",
    "            test_data['init_params_std_mean'][k] = mean_2\n",
    "            total_1 += mean_1\n",
    "            total_2 += mean_2\n",
    "            count += 1\n",
    "\n",
    "for k in range(test_data.shape[0]):\n",
    "    if my_filter['init_params_std'][k]:\n",
    "        test_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_std_mean'][k] = total_2 / count\n",
    "    elif type(test_data['init_params_std'][k]) != str:\n",
    "        test_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_std_mean'][k] = total_2 / count\n",
    "    elif len(test_data['init_params_std'][k]) < 2:\n",
    "        test_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_std_mean'][k] = total_2 / count\n",
    "    elif test_data['init_params_std'][k][0] != '[':\n",
    "        test_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_std_mean'][k] = total_2 / count\n",
    "    elif test_data['init_params_std'][k][-1] != ']':\n",
    "        test_data['init_params_std_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_std_mean'][k] = total_2 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/yitao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total_1 = 0\n",
    "total_2 = 0\n",
    "for k in range(test_data.shape[0]):\n",
    "    if my_filter['init_params_l2'][k] == False:\n",
    "        if type(test_data['init_params_l2'][k]) == str and len(test_data['init_params_l2'][k]) >= 2 and test_data['init_params_l2'][k][0] == '[' and test_data['init_params_l2'][k][-1] == ']':\n",
    "            mean_1 = stat.stdev([float(i) for i in test_data['init_params_l2'][k][1:-1].split(',')])\n",
    "            mean_2 = stat.mean([float(i) for i in test_data['init_params_l2'][k][1:-1].split(',')])\n",
    "            test_data['init_params_l2_stdev'][k] = mean_1\n",
    "            test_data['init_params_l2_mean'][k] = mean_2\n",
    "            total_1 += mean_1\n",
    "            total_2 += mean_2\n",
    "            count += 1\n",
    "\n",
    "for k in range(test_data.shape[0]):\n",
    "    if my_filter['init_params_l2'][k]:\n",
    "        test_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_l2_mean'][k] = total_2 / count\n",
    "    elif type(test_data['init_params_l2'][k]) != str:\n",
    "        test_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_l2_mean'][k] = total_2 / count\n",
    "    elif len(test_data['init_params_l2'][k]) < 2:\n",
    "        test_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_l2_mean'][k] = total_2 / count\n",
    "    elif test_data['init_params_l2'][k][0] != '[':\n",
    "        test_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_l2_mean'][k] = total_2 / count\n",
    "    elif test_data['init_params_l2'][k][-1] != ']':\n",
    "        test_data['init_params_l2_stdev'][k] = total_1 / count\n",
    "        test_data['init_params_l2_mean'][k] = total_2 / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x1 = np.array(test_data[['init_params_mu_stdev', 'init_params_mu_mean', 'init_params_std_stdev', 'init_params_std_mean', 'init_params_l2_stdev', 'init_params_l2_mean',\n",
    "        'epochs', 'number_parameters', \n",
    "        'softmax', 'tanh', 'linear', 'dropout', 'batchnorm', 'flatten', 'conv', 'selu', 'leaky_relu', 'relu', 'maxpool',\n",
    "        'val_accs_0', 'val_accs_10', 'val_accs_20', 'val_accs_30', \n",
    "        'val_accs_40', 'val_accs_41', 'val_accs_42', 'val_accs_43', 'val_accs_44',\n",
    "       'val_accs_45', 'val_accs_46', 'val_accs_47', 'val_accs_48', 'val_accs_49',\n",
    "        'val_losses_0', 'val_losses_10', 'val_losses_20', 'val_losses_30', \n",
    "        'val_losses_40', 'val_losses_41', 'val_losses_42',\n",
    "       'val_losses_43', 'val_losses_44', 'val_losses_45', 'val_losses_46',\n",
    "       'val_losses_47', 'val_losses_48', 'val_losses_49']])\n",
    "test_x2 = np.array(test_data[['init_params_mu_stdev', 'init_params_mu_mean', 'init_params_std_stdev', 'init_params_std_mean', 'init_params_l2_stdev', 'init_params_l2_mean',\n",
    "        'epochs', 'number_parameters', \n",
    "        'softmax', 'tanh', 'linear', 'dropout', 'batchnorm', 'flatten', 'conv', 'selu', 'leaky_relu', 'relu', 'maxpool',\n",
    "        'train_accs_0', 'train_accs_10', 'train_accs_20', 'train_accs_30', \n",
    "       'train_accs_40', 'train_accs_41', 'train_accs_42', 'train_accs_43', 'train_accs_44',\n",
    "       'train_accs_45', 'train_accs_46', 'train_accs_47', 'train_accs_48', 'train_accs_49',\n",
    "        'train_losses_0', 'train_losses_10', 'train_losses_20', 'train_losses_30',\n",
    "        'train_losses_40', 'train_losses_41',\n",
    "       'train_losses_42', 'train_losses_43', 'train_losses_44',\n",
    "       'train_losses_45', 'train_losses_46', 'train_losses_47',\n",
    "       'train_losses_48', 'train_losses_49']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y1 = regr1.predict(test_x1)\n",
    "test_y2 = regr2.predict(test_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(test_y1.shape[0]):\n",
    "    y_pred.append(['test_' + str(i) + '_val_error', test_y1[i]])\n",
    "    y_pred.append(['test_' + str(i) + '_train_error', test_y2[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(y_pred, columns = ['id', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
